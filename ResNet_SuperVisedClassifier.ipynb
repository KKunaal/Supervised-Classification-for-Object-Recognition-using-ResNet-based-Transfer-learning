{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 7916,
     "status": "ok",
     "timestamp": 1610219387122,
     "user": {
      "displayName": "Kunal Ghanghav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgM8mJJ6ThEXlpX9LAczKoE__85AV61zjcdiOkBRg=s64",
      "userId": "09981725673881426471"
     },
     "user_tz": -330
    },
    "id": "xFrYQ0FUfHrc"
   },
   "outputs": [],
   "source": [
    "!pip install jovian --upgrade --quiet\n",
    "!pip install opendatasets --quiet\n",
    "!pip install shuttle --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 818,
     "status": "ok",
     "timestamp": 1610219389013,
     "user": {
      "displayName": "Kunal Ghanghav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgM8mJJ6ThEXlpX9LAczKoE__85AV61zjcdiOkBRg=s64",
      "userId": "09981725673881426471"
     },
     "user_tz": -330
    },
    "id": "0YSuvrg-fHrd"
   },
   "outputs": [],
   "source": [
    "project_name = 'cifar100-transfer-learning-resnet50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1183,
     "status": "ok",
     "timestamp": 1610219391402,
     "user": {
      "displayName": "Kunal Ghanghav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgM8mJJ6ThEXlpX9LAczKoE__85AV61zjcdiOkBRg=s64",
      "userId": "09981725673881426471"
     },
     "user_tz": -330
    },
    "id": "BPAsHUxkfRLV"
   },
   "outputs": [],
   "source": [
    "# lets import all required libraries\n",
    "\n",
    "import os,copy\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import shuttle\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchvision.transforms import transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision\n",
    "import opendatasets as od\n",
    "import torch\n",
    "import shuttle\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9730,
     "status": "ok",
     "timestamp": 1610219406878,
     "user": {
      "displayName": "Kunal Ghanghav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgM8mJJ6ThEXlpX9LAczKoE__85AV61zjcdiOkBRg=s64",
      "userId": "09981725673881426471"
     },
     "user_tz": -330
    },
    "id": "3TNQ7lq3fgNZ",
    "outputId": "7c8000fa-8516-4de5-e039-2577dee83b95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username: kunalghanghav\n",
      "Your Kaggle Key: ········\n",
      "Downloading cifar-100-images.zip to ./cifar-100-images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 140M/140M [00:02<00:00, 60.9MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# download data, Now I refer dataset from Kaggle\n",
    "dataset_url = 'https://www.kaggle.com/minbavel/cifar-100-images'\n",
    "od.download(dataset_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1655,
     "status": "ok",
     "timestamp": 1610219409246,
     "user": {
      "displayName": "Kunal Ghanghav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgM8mJJ6ThEXlpX9LAczKoE__85AV61zjcdiOkBRg=s64",
      "userId": "09981725673881426471"
     },
     "user_tz": -330
    },
    "id": "eVfssO4viTx5",
    "outputId": "cae3db57-5b74-46e0-ee4e-fca75def999d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categories in CIFAR100 are 100\n"
     ]
    }
   ],
   "source": [
    "data_dir = './cifar-100-images/CIFAR100/TRAIN'\n",
    "\n",
    "print(\"Number of categories in CIFAR100 are {}\".format(len(os.listdir(data_dir))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 2148,
     "status": "ok",
     "timestamp": 1610219412697,
     "user": {
      "displayName": "Kunal Ghanghav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgM8mJJ6ThEXlpX9LAczKoE__85AV61zjcdiOkBRg=s64",
      "userId": "09981725673881426471"
     },
     "user_tz": -330
    },
    "id": "cM-kuBODgqOM"
   },
   "outputs": [],
   "source": [
    "# lets see number of files in each category\n",
    "# for folder in sorted(os.listdir(data_dir)):\n",
    "#   path = data_dir+'/'+folder\n",
    "#   print(\"Number of files in {} category are {}\".format(folder,len(os.listdir(path))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "executionInfo": {
     "elapsed": 1435,
     "status": "error",
     "timestamp": 1610219414642,
     "user": {
      "displayName": "Kunal Ghanghav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgM8mJJ6ThEXlpX9LAczKoE__85AV61zjcdiOkBRg=s64",
      "userId": "09981725673881426471"
     },
     "user_tz": -330
    },
    "id": "FVJ-AoEYik1p",
    "outputId": "4a111b7b-ea29-4fb8-8667-33bdc9c8ca6c"
   },
   "outputs": [],
   "source": [
    "# As we have around 50000 images across 100 categories, lets keep 20% images, i.e 10000 images to validation\n",
    "# this creates all required folders, such as Val and their subfolders\n",
    "val_path = './cifar-100-images/CIFAR100/VAL'\n",
    "source_dir = './cifar-100-images/CIFAR100/TRAIN'\n",
    "\n",
    "os.mkdir(val_path)\n",
    "\n",
    "for i in sorted(os.listdir(source_dir)):\n",
    "  path = val_path+'/'+i\n",
    "  os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 1692,
     "status": "ok",
     "timestamp": 1610219441477,
     "user": {
      "displayName": "Kunal Ghanghav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgM8mJJ6ThEXlpX9LAczKoE__85AV61zjcdiOkBRg=s64",
      "userId": "09981725673881426471"
     },
     "user_tz": -330
    },
    "id": "BsbmNDYJn23X"
   },
   "outputs": [],
   "source": [
    "# This code copies random sample images from training folder to validation folder, it copies 100 such random images.\n",
    "for folder in sorted(os.listdir(source_dir)):\n",
    "  dest_path = val_path+'/'+folder\n",
    "  source_path = source_dir+'/'+folder\n",
    "\n",
    "  source_files = os.listdir(source_path)\n",
    "  randint = sorted(random.sample(range(500), 100))\n",
    "  # print(\"Random Integers \\n\",randint)\n",
    "  for file in randint:\n",
    "    source_file_name = source_path+'/'+source_files[file]\n",
    "    dest_file_name = dest_path+'/'+source_files[file]\n",
    "    os.rename(source_file_name,dest_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1965,
     "status": "ok",
     "timestamp": 1610219445679,
     "user": {
      "displayName": "Kunal Ghanghav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgM8mJJ6ThEXlpX9LAczKoE__85AV61zjcdiOkBRg=s64",
      "userId": "09981725673881426471"
     },
     "user_tz": -330
    },
    "id": "p8P2FfA9dWGs",
    "outputId": "4751a964-9cca-4522-cf4d-a90d6d5fde17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in Train folder are 40000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of files in Train folder are {}\".\n",
    "format(sum([len(os.listdir(data_dir+'/'+x)) for x in os.listdir(data_dir)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1275,
     "status": "ok",
     "timestamp": 1610219449282,
     "user": {
      "displayName": "Kunal Ghanghav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgM8mJJ6ThEXlpX9LAczKoE__85AV61zjcdiOkBRg=s64",
      "userId": "09981725673881426471"
     },
     "user_tz": -330
    },
    "id": "DeLVIlCYebXE",
    "outputId": "7fc96026-71b4-4adb-b685-14b89a210c89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in Validation folder are 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of files in Validation folder are {}\".\n",
    "format(sum([len(os.listdir(val_path+'/'+x)) for x in os.listdir(val_path)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 17842,
     "status": "aborted",
     "timestamp": 1610217019222,
     "user": {
      "displayName": "Kunal Ghanghav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgM8mJJ6ThEXlpX9LAczKoE__85AV61zjcdiOkBRg=s64",
      "userId": "09981725673881426471"
     },
     "user_tz": -330
    },
    "id": "XZDWpiUGfH4G"
   },
   "outputs": [],
   "source": [
    "# # we need to normalize the images, so we find mean and standard deviation for the images,\n",
    "# # https://www.youtube.com/watch?v=y6IEcEBRZks\n",
    "# # https://math.stackexchange.com/questions/3026285/why-does-operatornamevarx-ex2-ex2\n",
    "# # VAR[X] = E[X**2] - E[X]**2\n",
    "# def get_mean_std(loader):\n",
    "#   channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
    "\n",
    "#   for data, _ in loader:\n",
    "#     channels_sum += torch.mean(data, dim=[0,2,3])\n",
    "#     channels_squared_sum += torch.mean(data**2, dim=[0, 2, 3])\n",
    "#     num_batches += 1\n",
    "  \n",
    "#   mean = channels_sum / num_batches \n",
    "#   std = (channels_squared_sum / num_batches  - mean **2)**.5\n",
    "\n",
    "#   return mean, std\n",
    "\n",
    "# train_dl_for_mean_std = torch.utils.data.DataLoader(cifar100,batch_size=128,shuffle=True,num_workers=4, pin_memory=True)\n",
    "# stats=get_mean_std(train_dl_for_mean_std)\n",
    "# stats\n",
    "\n",
    "# stats = ((0.5071, 0.4866, 0.4409), (0.2673, 0.2564, 0.2762))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8x3Bvakp6uFV"
   },
   "source": [
    "data transforms helps model to become more generalized, lets apply transforms, Also As images might be of different sizes, keeping them in one size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 1323,
     "status": "ok",
     "timestamp": 1610219453146,
     "user": {
      "displayName": "Kunal Ghanghav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgM8mJJ6ThEXlpX9LAczKoE__85AV61zjcdiOkBRg=s64",
      "userId": "09981725673881426471"
     },
     "user_tz": -330
    },
    "id": "knZJWiXOe9Cb"
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'TRAIN': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5071, 0.4866, 0.4409], [0.2673, 0.2564, 0.2762])\n",
    "    ]),\n",
    "    'VAL': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5071, 0.4866, 0.4409], [0.2673, 0.2564, 0.2762])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NuhOrL547C2m"
   },
   "source": [
    "Creating torch datasets, along with data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 1573,
     "status": "ok",
     "timestamp": 1610219456321,
     "user": {
      "displayName": "Kunal Ghanghav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgM8mJJ6ThEXlpX9LAczKoE__85AV61zjcdiOkBRg=s64",
      "userId": "09981725673881426471"
     },
     "user_tz": -330
    },
    "id": "XVj7oh44fjwE"
   },
   "outputs": [],
   "source": [
    "data_dir = './cifar-100-images/CIFAR100/'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['TRAIN', 'VAL']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=128,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['TRAIN', 'VAL']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['TRAIN', 'VAL']}\n",
    "class_names = image_datasets['TRAIN'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZlGkBcUG7czi"
   },
   "source": [
    "writing helper function to display a sample of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 704
    },
    "executionInfo": {
     "elapsed": 5456,
     "status": "ok",
     "timestamp": 1610219463448,
     "user": {
      "displayName": "Kunal Ghanghav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgM8mJJ6ThEXlpX9LAczKoE__85AV61zjcdiOkBRg=s64",
      "userId": "09981725673881426471"
     },
     "user_tz": -330
    },
    "id": "z_CpngGVDJvv",
    "outputId": "029e3cfa-96a0-4871-dc12-a0d64a0ae91c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "\u0000ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "\u0000ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "\u0000ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "\u0000"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 160) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    935\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 160) is killed by signal: Bus error. It is possible that dataloader's workers are out of shared memory. Please try to raise your shared memory limit.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_58/1717046755.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TRAIN'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdenormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1001\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 160) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "inputs, classes = next(iter(dataloaders['TRAIN']))\n",
    "\n",
    "\n",
    "def denormalize(images, means, stds):\n",
    "    means = torch.tensor(means).reshape(1, 3, 1, 1)\n",
    "    stds = torch.tensor(stds).reshape(1, 3, 1, 1)\n",
    "    return images * stds + means\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "ax.set_xticks([]); ax.set_yticks([])\n",
    "denorm_images = denormalize(inputs, [0.5071, 0.4866, 0.4409],[0.2673, 0.2564, 0.2762])\n",
    "ax.imshow(torchvision.utils.make_grid(denorm_images[:64], nrow=8).permute(1, 2, 0).clamp(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 57
    },
    "executionInfo": {
     "elapsed": 5627,
     "status": "ok",
     "timestamp": 1610219474770,
     "user": {
      "displayName": "Kunal Ghanghav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgM8mJJ6ThEXlpX9LAczKoE__85AV61zjcdiOkBRg=s64",
      "userId": "09981725673881426471"
     },
     "user_tz": -330
    },
    "id": "5RUZ18ZOgJkL",
    "outputId": "94bc2a88-4cf4-4c60-dbe0-60b6efc42539"
   },
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.5071, 0.4866, 0.4409])\n",
    "    std = np.array([0.2673, 0.2564, 0.2762])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['TRAIN']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs,nrow=8)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8LPfaTb7qZI"
   },
   "source": [
    "Helper function to train the model, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3951,
     "status": "ok",
     "timestamp": 1610219489004,
     "user": {
      "displayName": "Kunal Ghanghav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgM8mJJ6ThEXlpX9LAczKoE__85AV61zjcdiOkBRg=s64",
      "userId": "09981725673881426471"
     },
     "user_tz": -330
    },
    "id": "0N80k26ggYom"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['TRAIN', 'VAL']:\n",
    "            if phase == 'TRAIN':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'TRAIN'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'TRAIN':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'VAL' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZgCsjgPZ8F4l"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1216,
     "status": "ok",
     "timestamp": 1610219495778,
     "user": {
      "displayName": "Kunal Ghanghav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgM8mJJ6ThEXlpX9LAczKoE__85AV61zjcdiOkBRg=s64",
      "userId": "09981725673881426471"
     },
     "user_tz": -330
    },
    "id": "zbTsY5W4gn0_"
   },
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['VAL']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gGOfctTm8H3R"
   },
   "source": [
    "As we applying Transfer learning, There are two ways to do transfer learning. \n",
    "\n",
    "**1. extracting the feature vectors from pretrained model**: Here we freeze the weights for all of the network except for final dense/fully connected layer. The final fully connected layer replaced with new one with random weights, only this particular layer gets trained.  \n",
    "\n",
    "**2. Finetuning the model**: Here we initialize the training network, and we change dense layer parameters, and use same architecture, and train them. Rest is as usual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsPxmwQz9Y0-"
   },
   "source": [
    "lets try with first way, freeze the network and weights except for last layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "7e67318971ce46438f4d698a7553ffe8",
      "276ab64f9f54452fa0bbaefb697180ba",
      "d47adf677561471187062c4b2cb269bc",
      "6e43a71d8cf24d1e85da7e98a95f2060",
      "f6d176d3c63b4be2bcb5d4d5fc93c690",
      "f1fa8b861330441c80df5eb5d9d42d60",
      "46e95738bbf046c2a5e272e38c2ed715",
      "213a1298cba2499db15327b97b0707fd"
     ]
    },
    "executionInfo": {
     "elapsed": 14341,
     "status": "ok",
     "timestamp": 1610219511820,
     "user": {
      "displayName": "Kunal Ghanghav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgM8mJJ6ThEXlpX9LAczKoE__85AV61zjcdiOkBRg=s64",
      "userId": "09981725673881426471"
     },
     "user_tz": -330
    },
    "id": "e3slFYh35CY4",
    "outputId": "4dd6406e-8e0a-4b7f-f998-77f404be4720"
   },
   "outputs": [],
   "source": [
    "model_conv = torchvision.models.resnet50(pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_conv = torch.optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WUj5MsJk5Q0e",
    "outputId": "6441f766-5a61-4998-803f-b933f735adf6"
   },
   "outputs": [],
   "source": [
    "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
    "                         exp_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17814,
     "status": "aborted",
     "timestamp": 1610217019232,
     "user": {
      "displayName": "Kunal Ghanghav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgM8mJJ6ThEXlpX9LAczKoE__85AV61zjcdiOkBRg=s64",
      "userId": "09981725673881426471"
     },
     "user_tz": -330
    },
    "id": "dj8sE7o_gsSA"
   },
   "outputs": [],
   "source": [
    "model_ft = torchvision.models.resnet50(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = torch.optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17810,
     "status": "aborted",
     "timestamp": 1610217019233,
     "user": {
      "displayName": "Kunal Ghanghav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgM8mJJ6ThEXlpX9LAczKoE__85AV61zjcdiOkBRg=s64",
      "userId": "09981725673881426471"
     },
     "user_tz": -330
    },
    "id": "E_96LugbhqNz"
   },
   "outputs": [],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17807,
     "status": "aborted",
     "timestamp": 1610217019234,
     "user": {
      "displayName": "Kunal Ghanghav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgM8mJJ6ThEXlpX9LAczKoE__85AV61zjcdiOkBRg=s64",
      "userId": "09981725673881426471"
     },
     "user_tz": -330
    },
    "id": "WnCDc6VMocn-"
   },
   "outputs": [],
   "source": [
    "jovian.commit(project=project_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fPWNkdAx99Re"
   },
   "source": [
    "We did see that with SGD optimizer, model is getting stuck at saddle points, we can try with Adam optimizer and see how does it work.\n",
    "\n",
    "We can go with fine training the model, by freezing the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17805,
     "status": "aborted",
     "timestamp": 1610217019236,
     "user": {
      "displayName": "Kunal Ghanghav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgM8mJJ6ThEXlpX9LAczKoE__85AV61zjcdiOkBRg=s64",
      "userId": "09981725673881426471"
     },
     "user_tz": -330
    },
    "id": "TGbAo2KHeya4"
   },
   "outputs": [],
   "source": [
    "model_conv = torchvision.models.resnet50(pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "weight_decay = 1e-4\n",
    "max_lr = 0.01\n",
    "epochs = 25\n",
    "optimizer_conv = torch.optim.Adam(model_conv.fc.parameters(), max_lr, weight_decay = weight_decay)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer_conv, max_lr, epochs=epochs, \n",
    "                                                       steps_per_epoch=len(dataloaders['TRAIN']))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "blank-starter.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "213a1298cba2499db15327b97b0707fd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "276ab64f9f54452fa0bbaefb697180ba": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46e95738bbf046c2a5e272e38c2ed715": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6e43a71d8cf24d1e85da7e98a95f2060": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_213a1298cba2499db15327b97b0707fd",
      "placeholder": "​",
      "style": "IPY_MODEL_46e95738bbf046c2a5e272e38c2ed715",
      "value": " 97.8M/97.8M [00:00&lt;00:00, 197MB/s]"
     }
    },
    "7e67318971ce46438f4d698a7553ffe8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d47adf677561471187062c4b2cb269bc",
       "IPY_MODEL_6e43a71d8cf24d1e85da7e98a95f2060"
      ],
      "layout": "IPY_MODEL_276ab64f9f54452fa0bbaefb697180ba"
     }
    },
    "d47adf677561471187062c4b2cb269bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f1fa8b861330441c80df5eb5d9d42d60",
      "max": 102502400,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f6d176d3c63b4be2bcb5d4d5fc93c690",
      "value": 102502400
     }
    },
    "f1fa8b861330441c80df5eb5d9d42d60": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6d176d3c63b4be2bcb5d4d5fc93c690": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
